### 现象：

Kubernetes 是怎么限制每个容器 CPU 使用的？

### 原因：

Kubernetes 会为每个容器都在 CPU Cgroup 的子系统中建立一个控制组，然后把容器中进程写入到这个控制组里。
最终通过以下几个参数控制使用：

- cpu.shares：这个值决定了 CPU Cgroup 子系统下控制组可用 CPU 的相对比例（== request）
- cpu.cfs_quota_us/cpu.cfs_period_us：cpu.cfs_quota_us 和 cpu.cfs_period_us（固定 100000） 这两个值决定了每个控制组中所有进程的可使用 CPU 资源的最大值（== limit）

### 知识理解：

- request.cpu、limit.cpu 和 cpu.shares、cpu.cfs_quota_us 这几个参数是相关的

```shell
# 从 Pod 的 Yaml 查看 node IP 和 pod UID
"nodeName": "10.166.50.207",
"uid": "cd3b9021-d14b-43dd-8704-235db6716895",

# 从 Node 上查看 Pod 的 CPU cgroup 参数
# cat /sys/fs/cgroup/cpu/kubepods/burstable/podcd3b9021-d14b-43dd-8704-235db6716895/cpu.shares
409
# cat /sys/fs/cgroup/cpu/kubepods/burstable/podcd3b9021-d14b-43dd-8704-235db6716895/cpu.cfs_quota_us
400000

# 计算：
# request = 409 / 1024 = 0.4
# limit = 400000 / 100000 = 4
```

- 普通进程也可以实现 CPU 限额，只是需要手动配置

```shell
# cd /sys/fs/cgroup/cpu/
# mkdir group1 group2
# cd group2
# mkdir group3 group4

# ./threads-cpu 2 &
# top
    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
   2038 root      20   0   43608    620    536 S 300.0   0.0   2:43.76 threads-cpu

# echo $! > /sys/fs/cgroup/cpu/group2/group3/cgroup.procs
# echo 150000 > /sys/fs/cgroup/cpu/group2/group3/cpu.cfs_quota_us
# echo 1024 > /sys/fs/cgroup/cpu/group2/group3/cpu.shares
# top
    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
   2038 root      20   0   43608    620    536 S 142.2   0.0   4:08.87 threads-cpu

# 计算：
# limit.cpu = 150000 / 100000 = 1.5

# ./threads-cpu/threads-cpu 4 &  # 启动一个消耗4个CPU的程序
# echo $! > /sys/fs/cgroup/cpu/group2/group4/cgroup.procs #把程序的pid加入到控制组
# echo 350000 > /sys/fs/cgroup/cpu/group2/group4/cpu.cfs_quota_us #限制CPU为1.5CPU
# echo 3072 > /sys/fs/cgroup/cpu/group2/group4/cpu.shares

# 计算：
# limit.cpu = 350000 / 100000 = 3.5
# group3.request.cpu / group4.request.cpu = 3072 / 1024 = 3:1

```
